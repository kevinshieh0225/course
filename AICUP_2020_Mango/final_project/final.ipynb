{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU State: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import gc\n",
    "\n",
    "import PIL\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import torch.utils.data as Data\n",
    "from torch.utils.data.sampler import Sampler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "from torch.nn import Linear, ReLU, CrossEntropyLoss, Conv2d, MaxPool2d, Module\n",
    "from torch.optim import Adam\n",
    "from tqdm.notebook import tqdm as tqdm\n",
    "from ipywidgets import IntProgress\n",
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "print('GPU State:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myDataset(Dataset):\n",
    "    def __init__(self, x, y, transform):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = cv2.imread(self.x[idx], cv2.IMREAD_COLOR)\n",
    "        if img is None:\n",
    "            print('Not found img : ', self.x[idx])\n",
    "        img = Image.fromarray(img)\n",
    "        img = self.transform(img)\n",
    "        return img, self.y[idx]\n",
    "    def target(self, slice_arr):\n",
    "        tar = []\n",
    "        for idx in slice_arr:\n",
    "            tar.append(self.y[idx])\n",
    "        return tar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 load and cut：讀檔並切芒果\n",
    "## output : cut_img, label_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./../C2_TrainDev/Dev/26519.jpg', './../C2_TrainDev/Dev/39995.jpg']\n",
      "Start Cutting\n",
      "Already have cut mango!\n",
      "Already have cut mango!\n",
      "['./../C2_TrainDev_After_Cut/Dev/26519.jpg', './../C2_TrainDev_After_Cut/Dev/39995.jpg']\n",
      "Finish Cutting\n",
      "[[0, 1, 0, 0, 0], [0, 1, 0, 0, 0], [0, 1, 0, 0, 0], [0, 1, 0, 1, 0], [0, 1, 0, 0, 0], [0, 1, 1, 0, 0], [0, 1, 0, 0, 0], [0, 1, 0, 0, 0], [0, 1, 0, 1, 0], [0, 1, 0, 1, 0]]\n",
      "29449\n",
      "29449\n"
     ]
    }
   ],
   "source": [
    "import cut\n",
    "\n",
    "# 1.1 load and cut：讀檔並切芒果\n",
    "## output : cut_img, label_index\n",
    "\n",
    "dir_path = \"./../C2_TrainDev\"\n",
    "dest = \"./../C2_TrainDev_After_Cut\"\n",
    "\n",
    "subdir = ['Dev', 'Train']\n",
    "for sub in subdir:\n",
    "    new_dir = os.path.join(dest, sub)\n",
    "    if not os.path.isdir(new_dir):\n",
    "      try:\n",
    "          os.makedirs(new_dir)\n",
    "      except OSError as e:\n",
    "          print(e)\n",
    "      else:\n",
    "          print(f\"Successfully created the directory {new_dir}\")\n",
    "path_train, box_train, label_train = cut.load_mango_csv(csv_path=f'{dir_path}/train.csv',dir_path = dir_path)\n",
    "path_dev, box_dev, label_dev = cut.load_mango_csv(csv_path=f'{dir_path}/dev.csv',dir_path = dir_path)\n",
    "print(path_dev[:2])\n",
    "print('Start Cutting')\n",
    "cut_img_train = cut.cut_mango(path_train, dest=dest, isCut=True, box=box_train)\n",
    "cut_img_dev = cut.cut_mango(path_dev, dest=dest, isCut=True, box=box_dev)\n",
    "print(cut_img_dev[:2])\n",
    "print('Finish Cutting')\n",
    "\n",
    "label2idx = {\n",
    "    '不良-乳汁吸附': 0,\n",
    "    '不良-機械傷害': 1,\n",
    "    '不良-炭疽病': 2,\n",
    "    '不良-著色不佳': 3,\n",
    "    '不良-黑斑病': 4\n",
    "}\n",
    "label_index = label_train + label_dev\n",
    "label = []\n",
    "for check in label_index:\n",
    "    new = [0,0,0,0,0]\n",
    "    for check_ in check:\n",
    "        new[label2idx[check_]] = 1\n",
    "    label.append(new)\n",
    "print(label[:10])  \n",
    "\n",
    "path = cut_img_train + cut_img_dev\n",
    "print(len(path))\n",
    "print(len(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./../C2_TrainDev/Train/38414.jpg', './../C2_TrainDev/Train/03182.jpg', './../C2_TrainDev/Train/29863.jpg', './../C2_TrainDev/Train/17937.jpg', './../C2_TrainDev/Train/40878.jpg', './../C2_TrainDev/Train/29064.jpg', './../C2_TrainDev/Train/33963.jpg', './../C2_TrainDev/Train/44680.jpg', './../C2_TrainDev/Train/35482.jpg', './../C2_TrainDev/Train/04406.jpg']\n",
      "[[[46.0, 146.0, 576.0, 574.0]], [[581.0, 277.0, 97.0, 93.0]], [[514.0, 538.0, 117.0, 144.0]], [[658.0, 263.0, 59.0, 74.0], [374.0, 243.0, 609.0, 334.0]], [[432.0, 160.0, 116.0, 132.0], [620.0, 289.0, 104.0, 100.0], [712.0, 161.0, 60.0, 65.0]], [[573.0, 236.0, 68.0, 46.0], [394.0, 226.0, 127.0, 96.0], [350.0, 103.0, 116.0, 52.0]], [[527.0, 307.0, 239.0, 154.0]], [[441.0, 72.0, 347.0, 547.0], [190.0, 60.0, 232.0, 197.0]], [[509.0, 443.0, 73.0, 57.0], [409.0, 509.0, 235.0, 98.0]], [[563.0, 100.0, 89.0, 158.0], [822.0, 125.0, 231.0, 570.0]]]\n",
      "[['不良-機械傷害'], ['不良-機械傷害'], ['不良-機械傷害'], ['不良-機械傷害', '不良-著色不佳'], ['不良-機械傷害', '不良-機械傷害', '不良-機械傷害'], ['不良-炭疽病', '不良-炭疽病', '不良-機械傷害'], ['不良-機械傷害'], ['不良-機械傷害', '不良-機械傷害'], ['不良-機械傷害', '不良-著色不佳'], ['不良-機械傷害', '不良-著色不佳']]\n",
      "['./../C2_TrainDev_After_Cut/Train/38414.jpg', './../C2_TrainDev_After_Cut/Train/03182.jpg', './../C2_TrainDev_After_Cut/Train/29863.jpg']\n",
      "25768\n"
     ]
    }
   ],
   "source": [
    "print(path[:10])\n",
    "print(box[:10])\n",
    "print(label[:10])\n",
    "print(cut_img[:3])\n",
    "print(len(cut_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 1, 0, 0, 0], [0, 1, 0, 0, 0], [0, 1, 0, 0, 0], [0, 1, 0, 1, 0], [0, 1, 0, 0, 0], [0, 1, 1, 0, 0], [0, 1, 0, 0, 0], [0, 1, 0, 0, 0], [0, 1, 0, 1, 0], [0, 1, 0, 1, 0]]\n"
     ]
    }
   ],
   "source": [
    "label2idx = {\n",
    "    '不良-乳汁吸附': 0,\n",
    "    '不良-機械傷害': 1,\n",
    "    '不良-炭疽病': 2,\n",
    "    '不良-著色不佳': 3,\n",
    "    '不良-黑斑病': 4\n",
    "}\n",
    "label_index = []\n",
    "for check in label:\n",
    "    new = [0,0,0,0,0]\n",
    "    for check_ in check:\n",
    "        new[label2idx[check_]] = 1\n",
    "    label_index.append(new)\n",
    "print(label_index[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2 不切芒果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mango_csv(csv_path='../C2_TrainDev/train.csv'):\n",
    "    label2idx = {\n",
    "    '不良-乳汁吸附': 0,\n",
    "    '不良-機械傷害': 1,\n",
    "    '不良-炭疽病': 2,\n",
    "    '不良-著色不佳': 3,\n",
    "    '不良-黑斑病': 4\n",
    "    }\n",
    "    path = []\n",
    "    box = []\n",
    "    label = []\n",
    "    subdir = csv_path.split('/')[-1].split('.')[0].capitalize() #[-1]意思是倒數最後一col，.capitalize()將首英文字母大寫，其他小寫\n",
    "    folder = '../C2_TrainDev/'\n",
    "    # subdir : Train , Dev\n",
    "    # 此時我需要的輸出格式為：\n",
    "    # path: 照片路徑 : ./Train/img.jpg\n",
    "    # label: 標籤  : [1,0,0,0,0]\n",
    "    resize_folder = f'{folder}resize/'\n",
    "    if not os.path.isdir(resize_folder):\n",
    "        os.makedirs(resize_folder)\n",
    "    with open(csv_path, 'r', encoding='utf8') as f:        \n",
    "        for line in tqdm(f):\n",
    "            clean_line = re.sub(',+\\n', '', line).replace('\\n', '').replace('\\ufeff', '').split(',')\n",
    "            curr_img_path = f'{folder}{subdir}/{clean_line[0]}'\n",
    "            new_img_path = f'{resize_folder}{subdir}{clean_line[0]}'\n",
    "            column = 5\n",
    "            curr_label = [0,0,0,0,0]\n",
    "            while column <= len(clean_line):\n",
    "              symptom = clean_line[column]\n",
    "              if symptom in label2idx:\n",
    "                curr_label[label2idx[symptom]] = 1\n",
    "              column += 5\n",
    "            if not os.path.isfile(curr_img_path):\n",
    "                print(f'No file for path : {curr_img_path}')\n",
    "                continue\n",
    "            if not os.path.isfile(new_img_path):\n",
    "                img = cv2.imread(curr_img_path, cv2.IMREAD_COLOR)\n",
    "                img = cv2.resize(img, (224, 224), interpolation=cv2.INTER_AREA)\n",
    "                cv2.imwrite(new_img_path, img)\n",
    "            path.append(new_img_path)\n",
    "            label.append(curr_label)\n",
    "    print('data size: ')\n",
    "    print(len(path), len(label))\n",
    "    print(path[:6])\n",
    "    print(label[:6])\n",
    "    count = np.zeros(5)\n",
    "    for check in label:\n",
    "      count += np.array(check)\n",
    "    print('不良-乳汁吸附：'+str(count[0])+' '+str(count[0]/len(label)))\n",
    "    print('不良-機械傷害：'+str(count[1])+' '+str(count[1]/len(label)))\n",
    "    print('不良-炭疽病：'+str(count[2])+' '+str(count[2]/len(label)))\n",
    "    print('不良-著色不佳：'+str(count[3])+' '+str(count[3]/len(label)))\n",
    "    print('不良-黑斑病：'+str(count[4])+' '+str(count[4]/len(label)))\n",
    "    print()\n",
    "    return path, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0df2cb11541547989ebc5a1ec3fa0ee3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "data size: \n",
      "25768 25768\n",
      "['../C2_TrainDev/resize/Train38414.jpg', '../C2_TrainDev/resize/Train03182.jpg', '../C2_TrainDev/resize/Train29863.jpg', '../C2_TrainDev/resize/Train17937.jpg', '../C2_TrainDev/resize/Train40878.jpg', '../C2_TrainDev/resize/Train29064.jpg']\n",
      "[[0, 1, 0, 0, 0], [0, 1, 0, 0, 0], [0, 1, 0, 0, 0], [0, 1, 0, 1, 0], [0, 1, 0, 0, 0], [0, 1, 1, 0, 0]]\n",
      "不良-乳汁吸附：2122.0 0.08235020180068302\n",
      "不良-機械傷害：419.0 0.01626047811238746\n",
      "不良-炭疽病：11489.0 0.44586308599813723\n",
      "不良-著色不佳：14515.0 0.5632955603849736\n",
      "不良-黑斑病：953.0 0.036983855945358586\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08c4d43f2f9f4da99ebfa0e258f1bea6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "data size: \n",
      "3681 3681\n",
      "['../C2_TrainDev/resize/Dev26519.jpg', '../C2_TrainDev/resize/Dev39995.jpg', '../C2_TrainDev/resize/Dev40837.jpg', '../C2_TrainDev/resize/Dev09242.jpg', '../C2_TrainDev/resize/Dev22304.jpg', '../C2_TrainDev/resize/Dev04118.jpg']\n",
      "[[0, 1, 1, 0, 0], [0, 1, 1, 0, 0], [0, 1, 1, 0, 0], [1, 1, 1, 0, 0], [0, 1, 1, 0, 0], [0, 1, 1, 0, 1]]\n",
      "不良-乳汁吸附：308.0 0.08367291496875849\n",
      "不良-機械傷害：60.0 0.016299918500407497\n",
      "不良-炭疽病：1765.0 0.4794892692203206\n",
      "不良-著色不佳：1938.0 0.5264873675631622\n",
      "不良-黑斑病：170.0 0.04618310241782125\n",
      "\n",
      "29449\n",
      "29449\n",
      "['../C2_TrainDev/resize/Train38414.jpg', '../C2_TrainDev/resize/Train03182.jpg', '../C2_TrainDev/resize/Train29863.jpg', '../C2_TrainDev/resize/Train17937.jpg', '../C2_TrainDev/resize/Train40878.jpg']\n",
      "[[0, 1, 0, 0, 0], [0, 1, 0, 0, 0], [0, 1, 0, 0, 0], [0, 1, 0, 1, 0], [0, 1, 0, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "path_train , label_train = load_mango_csv()\n",
    "path_dev , label_dev = load_mango_csv(csv_path='../C2_TrainDev/dev.csv')\n",
    "\n",
    "path = path_train + path_dev\n",
    "label = label_train + label_dev\n",
    "print(len(path))\n",
    "print(len(label))\n",
    "print(path[:5])\n",
    "print(label[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. binary classification and balanced：把五類分開來，變成（1,0）問題\n",
    "## 使multi-label 成為 five binary-class problem\n",
    "## output : 分成五類的 dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def images_aug_balanced(cut_img , label_index ,label,transform,batchsize):\n",
    "    \n",
    "    data_x = []\n",
    "    data_y = []\n",
    "    minority_num = 0\n",
    "    majority_num = 0\n",
    "    for img_path , label_indices in zip(cut_img , label_index):\n",
    "        if label_indices[label] == 1:\n",
    "            data_y.append(1) \n",
    "            minority_num += 1\n",
    "        else: \n",
    "            data_y.append(0)\n",
    "            majority_num += 1\n",
    "        data_x.append(img_path)\n",
    "    \n",
    "    dataset = myDataset(data_x, data_y, transform)\n",
    "    \n",
    "    #切分70%當作訓練集、30%當作驗證集\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    valid_size = len(dataset) - train_size\n",
    "    trainset = {}\n",
    "    trainset['train'],trainset['valid'] = torch.utils.data.random_split(dataset, [train_size, valid_size])\n",
    "    \n",
    "    minority_weight = 1/minority_num\n",
    "    majority_weight = 1/majority_num\n",
    "    print(f'1:{minority_weight} , 0:{majority_weight}')\n",
    "    sample_weights = np.array([majority_weight, minority_weight])\n",
    "    \n",
    "    trainloader = {}\n",
    "    labels = trainset['train'].dataset.target(trainset['train'].indices)\n",
    "    labels = list(map(int, labels))\n",
    "    weights = sample_weights[labels]\n",
    "    print(f'train stage balanced')\n",
    "    print(f'weights:{weights[:50]}')\n",
    "    print(f'len:{len(weights)}\\n\\n')\n",
    "    num_samples = len(trainset['train']) #if minority_num*4 > majority_num else int(len(trainset['train'])*(minority_num/(minority_num+majority_num))*8)\n",
    "    sampler = Data.WeightedRandomSampler(weights=weights,num_samples = num_samples)\n",
    "    trainloader['train'] = DataLoader(trainset['train'], batch_size = batchsize, sampler=sampler)\n",
    "    \n",
    "    trainloader['valid'] = DataLoader(trainset['valid'], batch_size = batchsize)\n",
    "    \n",
    "    return trainloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:0.000471253534401508 , 0:4.22904508162057e-05\n",
      "train stage balanced\n",
      "weights:[4.22904508e-05 4.22904508e-05 4.22904508e-05 4.22904508e-05\n",
      " 4.22904508e-05 4.22904508e-05 4.22904508e-05 4.22904508e-05\n",
      " 4.22904508e-05 4.22904508e-05 4.22904508e-05 4.22904508e-05\n",
      " 4.22904508e-05 4.22904508e-05 4.71253534e-04 4.22904508e-05\n",
      " 4.22904508e-05 4.22904508e-05 4.22904508e-05 4.22904508e-05\n",
      " 4.22904508e-05 4.71253534e-04 4.22904508e-05 4.22904508e-05\n",
      " 4.22904508e-05 4.22904508e-05 4.22904508e-05 4.22904508e-05\n",
      " 4.22904508e-05 4.22904508e-05 4.22904508e-05 4.22904508e-05\n",
      " 4.22904508e-05 4.22904508e-05 4.22904508e-05 4.22904508e-05\n",
      " 4.22904508e-05 4.22904508e-05 4.22904508e-05 4.22904508e-05\n",
      " 4.22904508e-05 4.22904508e-05 4.22904508e-05 4.22904508e-05\n",
      " 4.22904508e-05 4.22904508e-05 4.22904508e-05 4.22904508e-05\n",
      " 4.22904508e-05 4.22904508e-05]\n",
      "len:18037\n",
      "\n",
      "\n",
      "1:0.002386634844868735 , 0:3.9449287940352674e-05\n",
      "train stage balanced\n",
      "weights:[3.94492879e-05 3.94492879e-05 3.94492879e-05 3.94492879e-05\n",
      " 3.94492879e-05 3.94492879e-05 3.94492879e-05 3.94492879e-05\n",
      " 3.94492879e-05 3.94492879e-05 3.94492879e-05 3.94492879e-05\n",
      " 3.94492879e-05 3.94492879e-05 3.94492879e-05 3.94492879e-05\n",
      " 3.94492879e-05 3.94492879e-05 3.94492879e-05 3.94492879e-05\n",
      " 3.94492879e-05 3.94492879e-05 3.94492879e-05 3.94492879e-05\n",
      " 3.94492879e-05 3.94492879e-05 3.94492879e-05 3.94492879e-05\n",
      " 3.94492879e-05 3.94492879e-05 3.94492879e-05 3.94492879e-05\n",
      " 3.94492879e-05 3.94492879e-05 3.94492879e-05 3.94492879e-05\n",
      " 3.94492879e-05 3.94492879e-05 3.94492879e-05 3.94492879e-05\n",
      " 3.94492879e-05 3.94492879e-05 3.94492879e-05 3.94492879e-05\n",
      " 3.94492879e-05 3.94492879e-05 3.94492879e-05 3.94492879e-05\n",
      " 3.94492879e-05 3.94492879e-05]\n",
      "len:18037\n",
      "\n",
      "\n",
      "1:8.703977717817043e-05 , 0:7.003291547027102e-05\n",
      "train stage balanced\n",
      "weights:[8.70397772e-05 8.70397772e-05 8.70397772e-05 8.70397772e-05\n",
      " 7.00329155e-05 7.00329155e-05 8.70397772e-05 7.00329155e-05\n",
      " 7.00329155e-05 7.00329155e-05 8.70397772e-05 7.00329155e-05\n",
      " 8.70397772e-05 7.00329155e-05 8.70397772e-05 8.70397772e-05\n",
      " 7.00329155e-05 8.70397772e-05 7.00329155e-05 7.00329155e-05\n",
      " 7.00329155e-05 7.00329155e-05 7.00329155e-05 7.00329155e-05\n",
      " 8.70397772e-05 7.00329155e-05 7.00329155e-05 8.70397772e-05\n",
      " 8.70397772e-05 7.00329155e-05 8.70397772e-05 7.00329155e-05\n",
      " 8.70397772e-05 7.00329155e-05 7.00329155e-05 8.70397772e-05\n",
      " 8.70397772e-05 8.70397772e-05 8.70397772e-05 8.70397772e-05\n",
      " 8.70397772e-05 7.00329155e-05 7.00329155e-05 8.70397772e-05\n",
      " 8.70397772e-05 8.70397772e-05 7.00329155e-05 8.70397772e-05\n",
      " 7.00329155e-05 7.00329155e-05]\n",
      "len:18037\n",
      "\n",
      "\n",
      "1:6.889424733034792e-05 , 0:8.88651915044877e-05\n",
      "train stage balanced\n",
      "weights:[6.88942473e-05 8.88651915e-05 8.88651915e-05 8.88651915e-05\n",
      " 6.88942473e-05 6.88942473e-05 8.88651915e-05 8.88651915e-05\n",
      " 6.88942473e-05 6.88942473e-05 6.88942473e-05 8.88651915e-05\n",
      " 8.88651915e-05 8.88651915e-05 6.88942473e-05 6.88942473e-05\n",
      " 8.88651915e-05 8.88651915e-05 6.88942473e-05 6.88942473e-05\n",
      " 6.88942473e-05 8.88651915e-05 6.88942473e-05 8.88651915e-05\n",
      " 8.88651915e-05 6.88942473e-05 8.88651915e-05 6.88942473e-05\n",
      " 8.88651915e-05 6.88942473e-05 6.88942473e-05 8.88651915e-05\n",
      " 6.88942473e-05 6.88942473e-05 8.88651915e-05 8.88651915e-05\n",
      " 8.88651915e-05 8.88651915e-05 6.88942473e-05 6.88942473e-05\n",
      " 8.88651915e-05 8.88651915e-05 6.88942473e-05 6.88942473e-05\n",
      " 6.88942473e-05 6.88942473e-05 8.88651915e-05 8.88651915e-05\n",
      " 6.88942473e-05 8.88651915e-05]\n",
      "len:18037\n",
      "\n",
      "\n",
      "1:0.001049317943336831 , 0:4.029820672980052e-05\n",
      "train stage balanced\n",
      "weights:[1.04931794e-03 4.02982067e-05 4.02982067e-05 4.02982067e-05\n",
      " 1.04931794e-03 4.02982067e-05 4.02982067e-05 4.02982067e-05\n",
      " 4.02982067e-05 4.02982067e-05 4.02982067e-05 4.02982067e-05\n",
      " 4.02982067e-05 4.02982067e-05 4.02982067e-05 4.02982067e-05\n",
      " 4.02982067e-05 4.02982067e-05 4.02982067e-05 4.02982067e-05\n",
      " 4.02982067e-05 1.04931794e-03 4.02982067e-05 4.02982067e-05\n",
      " 4.02982067e-05 4.02982067e-05 4.02982067e-05 4.02982067e-05\n",
      " 4.02982067e-05 4.02982067e-05 4.02982067e-05 4.02982067e-05\n",
      " 4.02982067e-05 4.02982067e-05 4.02982067e-05 4.02982067e-05\n",
      " 4.02982067e-05 4.02982067e-05 4.02982067e-05 4.02982067e-05\n",
      " 4.02982067e-05 4.02982067e-05 4.02982067e-05 4.02982067e-05\n",
      " 4.02982067e-05 4.02982067e-05 4.02982067e-05 4.02982067e-05\n",
      " 4.02982067e-05 4.02982067e-05]\n",
      "len:18037\n",
      "\n",
      "\n",
      "len of 0 train:141 from 18048\n",
      "len of 1 train:141 from 18048\n",
      "len of 2 train:141 from 18048\n",
      "len of 3 train:141 from 18048\n",
      "len of 4 train:141 from 18048\n",
      "\n",
      "len of 0 valid:61 from 7808\n",
      "len of 1 valid:61 from 7808\n",
      "len of 2 valid:61 from 7808\n",
      "len of 3 valid:61 from 7808\n",
      "len of 4 valid:61 from 7808\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# images_split = [[],[],[],[],[]]\n",
    "# for image_, label_ in zip(cut_img,label_index):\n",
    "#     for index,onezero in enumerate(label_):\n",
    "#         if onezero == 1:\n",
    "#             images_split[index].append(image_)\n",
    "# for injure_place, arr in zip(label2idx.items(),images_split):\n",
    "#     print(f'{injure_place}：{len(arr)}')\n",
    "\n",
    "transform = torchvision.transforms.Compose([\n",
    "torchvision.transforms.RandomHorizontalFlip(),\n",
    "torchvision.transforms.RandomRotation(15, resample=PIL.Image.BILINEAR),\n",
    "torchvision.transforms.ToTensor(),\n",
    "torchvision.transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "batchsize = 128\n",
    "dataloader_0 = images_aug_balanced(cut_img , label_index, 0, transform, batchsize)\n",
    "dataloader_1 = images_aug_balanced(cut_img , label_index, 1, transform, batchsize)\n",
    "dataloader_2 = images_aug_balanced(cut_img , label_index, 2, transform, batchsize)\n",
    "dataloader_3 = images_aug_balanced(cut_img , label_index, 3, transform, batchsize)\n",
    "dataloader_4 = images_aug_balanced(cut_img , label_index, 4, transform, batchsize)\n",
    "\n",
    "for stage in ['train' , 'valid']:\n",
    "    print(f'len of 0 {stage}:{len(dataloader_0[stage])} from {len(dataloader_0[stage])*batchsize}')\n",
    "    print(f'len of 1 {stage}:{len(dataloader_1[stage])} from {len(dataloader_1[stage])*batchsize}')\n",
    "    print(f'len of 2 {stage}:{len(dataloader_2[stage])} from {len(dataloader_2[stage])*batchsize}')\n",
    "    print(f'len of 3 {stage}:{len(dataloader_3[stage])} from {len(dataloader_3[stage])*batchsize}')\n",
    "    print(f'len of 4 {stage}:{len(dataloader_4[stage])} from {len(dataloader_4[stage])*batchsize}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 3, 1, 5, 2]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import TensorDataset as dataset\n",
    " \n",
    "list(data.WeightedRandomSampler([0.1, 0.9, 0.4, 0.7, 3.0, 0.6], 5, replacement=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train fine-tune model\n",
    "## 使用wide resnet50_2來進行pretrained\n",
    "## output : 五個ft wr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,name,n_epochs,train_loader,valid_loader,optimizer,criterion,batch_size,patience):\n",
    "    \"\"\"\n",
    "    intro:\n",
    "        每次epoch都 train the model , validate the model\n",
    "        並計算Early Stopping\n",
    "        印出 train_loss , train_acc , val_loss , val_acc\n",
    "        回傳 model\n",
    "    aug:\n",
    "        model,n_epochs,train_loader,valid_loader,optimizer,criterion,batch_size\n",
    "    output:\n",
    "        model\n",
    "    \"\"\"\n",
    "    \n",
    "    best_train_loss = 100\n",
    "    best_train_acc = 0\n",
    "    best_val_loss = 100\n",
    "    best_val_acc = 0\n",
    "    best_F1 = 0\n",
    "    last_epoch = 0\n",
    "    history = {\n",
    "        'accuracy':[],\n",
    "        'val_accuracy':[],\n",
    "        'loss':[],\n",
    "        'val_loss':[],\n",
    "        'precision':[],\n",
    "        'recall':[],\n",
    "        'f1':[]\n",
    "    }\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "    else:\n",
    "        print('no gpu use')\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        # keep track of training and validation loss\n",
    "        train_loss,valid_loss = 0.0,0.0\n",
    "        train_losses,valid_losses=[],[]\n",
    "        train_correct,val_correct,train_total,val_total=0,0,0,0\n",
    "        confusion_stacks = []\n",
    "\n",
    "        print('running epoch: {}'.format(epoch))\n",
    "        #############################################################################################################\n",
    "        #                                              train the model                                              #\n",
    "        #############################################################################################################\n",
    "        model.train()\n",
    "        for data, target in tqdm(train_loader):\n",
    "            # move tensors to GPU if CUDA is available\n",
    "            if torch.cuda.is_available():#train_on_gpu\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            else:\n",
    "                print('1')\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(data)\n",
    "            # calculate the batch loss\n",
    "            loss = criterion(output, target)\n",
    "            #calculate accuracy\n",
    "            pred = output.data.max(dim = 1, keepdim = True)[1]\n",
    "            train_correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n",
    "            train_total += data.size(0)\n",
    "            \n",
    "            # backward pass: compute gradient of the loss with respect to model parameters\n",
    "            loss.backward()\n",
    "            # perform a single optimization step (parameter update)\n",
    "            optimizer.step()\n",
    "            # update training loss\n",
    "            train_losses.append(loss.item()*data.size(0))\n",
    "            # clear the gradients of all optimized variables\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        #############################################################################################################\n",
    "        #                                            validate the model                                             #\n",
    "        #############################################################################################################\n",
    "        model.eval()\n",
    "        for data, target in tqdm(valid_loader):\n",
    "            # move tensors to GPU if CUDA is available\n",
    "            if torch.cuda.is_available():#train_on_gpu\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "                \n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(data)\n",
    "            # calculate the batch loss\n",
    "            loss =criterion(output, target)\n",
    "            #calculate accuracy\n",
    "            pred = output.data.max(dim = 1, keepdim = True)[1]\n",
    "            val_correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n",
    "            val_total += data.size(0)\n",
    "            # update validation loss\n",
    "            valid_losses.append(loss.item()*data.size(0))\n",
    "            \n",
    "            #confusion matrix\n",
    "            stacked = torch.stack((target,pred.t()[0]),dim=1)\n",
    "            confusion_stacks += stacked.cpu().detach().tolist()\n",
    "        \n",
    "        #############################################################################################################\n",
    "        #                                     print train/val/cmt epoch result                                      #\n",
    "        #############################################################################################################\n",
    "        # calculate average losses\n",
    "        train_loss=np.average(train_losses)\n",
    "        valid_loss=np.average(valid_losses)\n",
    "        # calculate average accuracy\n",
    "        train_acc=train_correct/train_total\n",
    "        valid_acc=val_correct/val_total\n",
    "        print(f'\\tTraining Loss: {train_loss:.3f} \\tValidation Loss: {valid_loss:.3f}')\n",
    "        print(f'\\tTraining Accuracy: {train_acc:.3f} \\tValidation Accuracy: {valid_acc:.3f}')\n",
    "        \n",
    "        cmt = torch.zeros(2,2, dtype=torch.int64)\n",
    "        for p in confusion_stacks:\n",
    "            tl, pl = p\n",
    "            cmt[tl, pl] = cmt[tl, pl] + 1\n",
    "        print(f'cmt\\tpred:0\\tpred:1\\nlabel:0\\t{cmt[0,0]}\\t{cmt[0,1]}\\nlabel:1\\t{cmt[1,0]}\\t{cmt[1,1]}\\n')\n",
    "        \n",
    "        TP = cmt[1,1]\n",
    "        FP = cmt[1,0]\n",
    "        FN = cmt[0,1]\n",
    "        TN = cmt[1,0]\n",
    "        \n",
    "        p = TP.double() / (TP.double() + FP.double())\n",
    "        r = TP.double() / (TP.double() + FN.double())\n",
    "        F1 = 2 * r * p / (r + p)\n",
    "        \n",
    "        print(f'precision = {p}\\trecall = {r}\\tF1 = {F1}\\n\\n')\n",
    "        \n",
    "        history['accuracy'].append(train_acc)\n",
    "        history['val_accuracy'].append(valid_acc)\n",
    "        history['loss'].append(train_loss)\n",
    "        history['val_loss'].append(valid_loss)\n",
    "        history['precision'].append(p)\n",
    "        history['recall'].append(r)\n",
    "        history['f1'].append(F1)\n",
    "        \n",
    "        #############################################################################################################\n",
    "        #                                              Early Stopping                                               #\n",
    "        #############################################################################################################\n",
    "        if valid_loss > best_val_loss:\n",
    "            trigger_times += 1\n",
    "            print(f'trigger times: {trigger_times}\\n')\n",
    "            if trigger_times > patience:\n",
    "                print(f'Early stopping at trigger times: {trigger_times}')\n",
    "                print(f'\\tLeast Training Loss: {best_train_loss:.4f} \\nLeast Validation Loss: {best_val_loss:.4f}')\n",
    "                print(f'\\tBest Training Accuracy: {best_train_acc:.4f} \\nBest Validation Accuracy: {best_val_acc:.4f}')\n",
    "                last_epoch = epoch\n",
    "                break\n",
    "        else:\n",
    "            trigger_times = 0\n",
    "            torch.save(model, f'./{name}.pt')\n",
    "            best_train_loss = train_loss\n",
    "            best_train_acc = train_acc\n",
    "            best_val_loss = valid_loss\n",
    "            best_val_acc = valid_acc\n",
    "    \n",
    "        #############################################################################################################\n",
    "        #                                                Draw picture                                               #\n",
    "        #############################################################################################################\n",
    "        \n",
    "    x = np.arange(1,last_epoch,1)\n",
    "    train_acc = history['accuracy']\n",
    "    val_acc = history['val_accuracy']\n",
    "    train_loss = history['loss']\n",
    "    val_loss = history['val_loss']\n",
    "    f1 = history['F1']\n",
    "    \n",
    "    fig = plt.figure(figsize=(12,4))\n",
    "    fig.subplots_adjust(hspace=0.4, wspace=0.3)\n",
    "\n",
    "    plt.subplot(2,2,1)\n",
    "    plt.title(\"Accuracy\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.plot(x, train_acc, label='training')\n",
    "    plt.plot(x, val_acc, label='validation')\n",
    "    plt.legend(loc='lower right')\n",
    "\n",
    "    plt.subplot(2,2,2)\n",
    "    plt.title(\"Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.plot(x, train_loss, label='training')\n",
    "    plt.plot(x, val_loss, label='validation')\n",
    "    plt.legend(loc='upper right')\n",
    "    \n",
    "    plt.subplot(2,2,3)\n",
    "    plt.title(\"F1-score\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"f1-score\")\n",
    "    plt.plot(x, f1, label='f1')\n",
    "    plt.legend(loc='upper right')\n",
    "    \n",
    "    model = torch.load(f'./{name}.pt')    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class 0 ：wide_resnet50_2 finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=2, bias=True)\n",
      ")\n",
      "running epoch: 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e664cdf761245aca216dd76797410da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=141.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 392.00 MiB (GPU 0; 10.76 GiB total capacity; 6.35 GiB already allocated; 198.25 MiB free; 6.86 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-aeba42df61bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mpatience\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mmodel_ft_wide_resnet50_class_0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_ft_wide_resnet50_class_0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'model_ft_wide_resnet50_class_0'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdataloader_0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdataloader_0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'valid'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-602920af13df>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, name, n_epochs, train_loader, valid_loader, optimizer, criterion, batch_size, patience)\u001b[0m\n\u001b[1;32m     51\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;31m# forward pass: compute predicted outputs by passing inputs to the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m             \u001b[0;31m# calculate the batch loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36m_forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0midentity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    344\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    345\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 346\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 392.00 MiB (GPU 0; 10.76 GiB total capacity; 6.35 GiB already allocated; 198.25 MiB free; 6.86 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "if os.path.isfile(f'./model_ft_wide_resnet50_class_0.pt'):\n",
    "    print(f'use finetune model_ft_wide_resnet50_class_0')\n",
    "    model_ft_wide_resnet50_class_0 = torch.load(f'./model_ft_wide_resnet50_class_0.pt')\n",
    "else:\n",
    "    model_ft_wide_resnet50_class_0 = models.wide_resnet50_2(pretrained=True)\n",
    "    num_ftrs = model_ft_wide_resnet50_class_0.fc.in_features\n",
    "    model_ft_wide_resnet50_class_0.fc = nn.Linear(num_ftrs,2)\n",
    "    model_ft_wide_resnet50_class_0 = model_ft_wide_resnet50_class_0.to(device)# 放入裝置\n",
    "    print(model_ft_wide_resnet50_class_0)\n",
    "\n",
    "n_epochs = 100\n",
    "batch_size = 64\n",
    "optimizer = torch.optim.Adam([\n",
    "    {'params':model_ft_wide_resnet50_class_0.parameters()}\n",
    "], lr=0.0001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "patience = 3\n",
    "\n",
    "model_ft_wide_resnet50_class_0=train(model_ft_wide_resnet50_class_0,'model_ft_wide_resnet50_class_0',n_epochs,dataloader_0['train'],dataloader_0['valid'],optimizer,criterion, batch_size , patience)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class 1 ：wide_resnet50_2 finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(f'./model_ft_wide_resnet50_class_1.pt'):\n",
    "    print(f'use finetune model_ft_wide_resnet50_class_1')\n",
    "    model_ft_wide_resnet50_class_1 = torch.load(f'./model_ft_wide_resnet50_class_1.pt')\n",
    "else:\n",
    "    model_ft_wide_resnet50_class_1 = models.wide_resnet50_2(pretrained=True)\n",
    "    num_ftrs = model_ft_wide_resnet50_class_1.fc.in_features\n",
    "    model_ft_wide_resnet50_class_1.fc = nn.Linear(num_ftrs,2)\n",
    "    model_ft_wide_resnet50_class_1 = model_ft_wide_resnet50_class_1.to(device)# 放入裝置\n",
    "    print(model_ft_wide_resnet50_class_1)\n",
    "\n",
    "n_epochs = 100\n",
    "batch_size = 16\n",
    "optimizer = torch.optim.Adam([\n",
    "    {'params':model_ft_wide_resnet50_class_1.parameters()}\n",
    "], lr=0.0001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "patience = 3\n",
    "model_ft_wide_resnet50_class_1=train(model_ft_wide_resnet50_class_1,'model_ft_wide_resnet50_class_1',n_epochs,dataloader_0['train'],dataloader_0['valid'],optimizer,criterion, batch_size , patience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1)\n",
      "tensor(1., dtype=torch.float64)\n",
      "1\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "cmt = torch.zeros(2,2, dtype=torch.int64)\n",
    "TP = cmt[0,0]+1\n",
    "print(TP)\n",
    "print(TP.double())\n",
    "print(TP.item())\n",
    "x = TP.item()/2\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3])\n",
      "torch.Size([3, 1])\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "target = torch.Tensor([1,1,1])\n",
    "print(target.shape)\n",
    "target = target.unsqueeze(1)\n",
    "print(target.shape)\n",
    "target = target.squeeze(1)\n",
    "print(target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.]])\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "output = [[0.51] , [0.39] , [0.] , [0.93]]\n",
    "target = [[1],[0],[1],[0]]\n",
    "\n",
    "output = torch.Tensor(output)\n",
    "target = torch.Tensor(target)\n",
    "\n",
    "y_pred_tag = torch.round(torch.sigmoid(output))\n",
    "print(y_pred_tag)\n",
    "correct_results_sum = (y_pred_tag == target).sum().int().item()\n",
    "print(correct_results_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 0.]])\n",
      "torch.float32\n",
      "[[1.0], [0.0], [1.0], [0.0]]\n"
     ]
    }
   ],
   "source": [
    "print(target.t())\n",
    "print(target.dtype)\n",
    "print(target.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_ft = models.wide_resnet50_2(pretrained=True)\n",
    "print(model_ft)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (3): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (4): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (5): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model_ft.layer3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "torch.float32\n",
      "torch.float32\n",
      "torch.float64\n",
      "torch.FloatTensor\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "expected dtype Double but got dtype Float (validate_dtype at /pytorch/aten/src/ATen/native/TensorIterator.cpp:143)\nframe #0: c10::Error::Error(c10::SourceLocation, std::string const&) + 0x46 (0x7f722a8cb536 in /usr/local/lib/python3.6/dist-packages/torch/lib/libc10.so)\nframe #1: at::TensorIterator::compute_types() + 0xce3 (0x7f7267feb183 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\nframe #2: at::TensorIterator::build() + 0x44 (0x7f7267fedb64 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\nframe #3: at::native::mse_loss_backward_out(at::Tensor&, at::Tensor const&, at::Tensor const&, at::Tensor const&, long) + 0x193 (0x7f7267e3bb93 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\nframe #4: <unknown function> + 0x10b7db7 (0x7f7268267db7 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\nframe #5: at::native::mse_loss_backward(at::Tensor const&, at::Tensor const&, at::Tensor const&, long) + 0x172 (0x7f7267e442d2 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\nframe #6: <unknown function> + 0x109e76f (0x7f726824e76f in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\nframe #7: <unknown function> + 0x10c3c76 (0x7f7268273c76 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\nframe #8: <unknown function> + 0x2a9eceb (0x7f7269c4eceb in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\nframe #9: <unknown function> + 0x10c3c76 (0x7f7268273c76 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\nframe #10: torch::autograd::generated::MseLossBackward::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x1f7 (0x7f7269a56787 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\nframe #11: <unknown function> + 0x2d89c05 (0x7f7269f39c05 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\nframe #12: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&) + 0x16f3 (0x7f7269f36f03 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\nframe #13: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&, bool) + 0x3d2 (0x7f7269f37ce2 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\nframe #14: torch::autograd::Engine::thread_init(int) + 0x39 (0x7f7269f30359 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\nframe #15: torch::autograd::python::PythonEngine::thread_init(int) + 0x38 (0x7f727666f4d8 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_python.so)\nframe #16: <unknown function> + 0xbd6df (0x7f73057586df in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)\nframe #17: <unknown function> + 0x76db (0x7f730b1146db in /lib/x86_64-linux-gnu/libpthread.so.0)\nframe #18: clone + 0x3f (0x7f730b44da3f in /lib/x86_64-linux-gnu/libc.so.6)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-143-b7803725d8f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m# print(loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expected dtype Double but got dtype Float (validate_dtype at /pytorch/aten/src/ATen/native/TensorIterator.cpp:143)\nframe #0: c10::Error::Error(c10::SourceLocation, std::string const&) + 0x46 (0x7f722a8cb536 in /usr/local/lib/python3.6/dist-packages/torch/lib/libc10.so)\nframe #1: at::TensorIterator::compute_types() + 0xce3 (0x7f7267feb183 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\nframe #2: at::TensorIterator::build() + 0x44 (0x7f7267fedb64 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\nframe #3: at::native::mse_loss_backward_out(at::Tensor&, at::Tensor const&, at::Tensor const&, at::Tensor const&, long) + 0x193 (0x7f7267e3bb93 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\nframe #4: <unknown function> + 0x10b7db7 (0x7f7268267db7 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\nframe #5: at::native::mse_loss_backward(at::Tensor const&, at::Tensor const&, at::Tensor const&, long) + 0x172 (0x7f7267e442d2 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\nframe #6: <unknown function> + 0x109e76f (0x7f726824e76f in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\nframe #7: <unknown function> + 0x10c3c76 (0x7f7268273c76 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\nframe #8: <unknown function> + 0x2a9eceb (0x7f7269c4eceb in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\nframe #9: <unknown function> + 0x10c3c76 (0x7f7268273c76 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\nframe #10: torch::autograd::generated::MseLossBackward::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x1f7 (0x7f7269a56787 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\nframe #11: <unknown function> + 0x2d89c05 (0x7f7269f39c05 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\nframe #12: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&) + 0x16f3 (0x7f7269f36f03 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\nframe #13: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&, bool) + 0x3d2 (0x7f7269f37ce2 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\nframe #14: torch::autograd::Engine::thread_init(int) + 0x39 (0x7f7269f30359 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\nframe #15: torch::autograd::python::PythonEngine::thread_init(int) + 0x38 (0x7f727666f4d8 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_python.so)\nframe #16: <unknown function> + 0xbd6df (0x7f73057586df in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)\nframe #17: <unknown function> + 0x76db (0x7f730b1146db in /lib/x86_64-linux-gnu/libpthread.so.0)\nframe #18: clone + 0x3f (0x7f730b44da3f in /lib/x86_64-linux-gnu/libc.so.6)\n"
     ]
    }
   ],
   "source": [
    "from torch.nn import Flatten\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "model_ft = models.wide_resnet50_2(pretrained=True)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs,1)\n",
    "model_ft=model_ft.to(device)# 放入裝置\n",
    "#model_ft = model_ft.float()\n",
    "#model = model.double()\n",
    "\n",
    "# mse_full = nn.MSELoss(reduction=\"none\")\n",
    "mse = nn.MSELoss()\n",
    "batch_datas = torch.randn(2, 3, 66, 220)\n",
    "batch_labels = torch.randn(2)\n",
    "print(type(batch_datas))\n",
    "print(type(batch_labels))\n",
    "                \n",
    "# # predict speed\n",
    "# pred = model(batch_datas)       \n",
    "# print(pred)\n",
    "# loss_each = mse_full( pred.flatten(), batch_labels )\n",
    "# print(loss_each)\n",
    "# loss_all = torch.mean(loss_each)\n",
    "# print(loss_all)\n",
    "# loss_all.backward()\n",
    "# print(loss_all)\n",
    "\n",
    "print(pred.flatten().dtype)\n",
    "print(batch_labels.dtype)\n",
    "batch_labels = batch_labels.double()\n",
    "print(batch_labels.dtype)\n",
    "\n",
    "pred = model(batch_datas)   \n",
    "loss = mse(pred.flatten(), batch_labels)\n",
    "\n",
    "# print(loss)\n",
    "loss.backward()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
